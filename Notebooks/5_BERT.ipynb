{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b594de4",
   "metadata": {},
   "source": [
    "https://medium.com/grabngoinfo/topic-modeling-with-deep-learning-using-python-bertopic-cf91f5676504"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b7a3b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic model\n",
    "from bertopic import BERTopic# Dimension reduction\n",
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d5626f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "from shared_globals_functions import *\n",
    "%aimport shared_globals_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e95fc13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, json\n",
    "import glob\n",
    "import operator\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1aaccda",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading /home/manuel/d3tect-tools/Notebooks/raw_testdata_v1/identified_repos_v1.pkl\n"
     ]
    }
   ],
   "source": [
    "identified_repos = from_disk(grtr)\n",
    "t_name = 't2.3.1s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce293c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading /home/manuel/d3tect-tools/Notebooks/raw_testdata_v1/t2.3.1s.pkl\n"
     ]
    }
   ],
   "source": [
    "testset = from_disk(t_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d35b492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "identified_repos_topics = pd.merge(identified_repos, testset[[\"name\", \"topics\"]], on=\"name\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "77850afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tag</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x4D31/awesome-threat-detection</td>\n",
       "      <td>secumon</td>\n",
       "      <td>connect logic spark trace instrument dispatch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xN3utr0n/Kanis</td>\n",
       "      <td>secumon</td>\n",
       "      <td>viruses elf sense information anomaly process ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>airbnb/binaryalert</td>\n",
       "      <td>secumon</td>\n",
       "      <td>aws threat match read status fire badge bucket...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>airbnb/streamalert</td>\n",
       "      <td>secumon</td>\n",
       "      <td>research aws automate source logic log support...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ait-aecid/logdata-anomaly-miner</td>\n",
       "      <td>secumon</td>\n",
       "      <td>raw information anomaly wiki deployment c ca d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>arch3rPro/PentestTools</td>\n",
       "      <td>pentest</td>\n",
       "      <td>connect page postgresql servers exe error java...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>whiterabb17/sifter</td>\n",
       "      <td>pentest</td>\n",
       "      <td>attack penetration code request information ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>hackThacker/advtools</td>\n",
       "      <td>pentest</td>\n",
       "      <td>attack pin code qr information website reverse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>rcallaby/Hacking-Study-Guide</td>\n",
       "      <td>pentest</td>\n",
       "      <td>attack systems windows role personal penetrati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>gotr00t0day/Gsec</td>\n",
       "      <td>pentest</td>\n",
       "      <td>subdomains code information cors program star ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                name      tag  \\\n",
       "0    0x4D31/awesome-threat-detection  secumon   \n",
       "1                    0xN3utr0n/Kanis  secumon   \n",
       "2                 airbnb/binaryalert  secumon   \n",
       "3                 airbnb/streamalert  secumon   \n",
       "4    ait-aecid/logdata-anomaly-miner  secumon   \n",
       "..                               ...      ...   \n",
       "115           arch3rPro/PentestTools  pentest   \n",
       "116               whiterabb17/sifter  pentest   \n",
       "117             hackThacker/advtools  pentest   \n",
       "118     rcallaby/Hacking-Study-Guide  pentest   \n",
       "119                 gotr00t0day/Gsec  pentest   \n",
       "\n",
       "                                                topics  \n",
       "0    connect logic spark trace instrument dispatch ...  \n",
       "1    viruses elf sense information anomaly process ...  \n",
       "2    aws threat match read status fire badge bucket...  \n",
       "3    research aws automate source logic log support...  \n",
       "4    raw information anomaly wiki deployment c ca d...  \n",
       "..                                                 ...  \n",
       "115  connect page postgresql servers exe error java...  \n",
       "116  attack penetration code request information ex...  \n",
       "117  attack pin code qr information website reverse...  \n",
       "118  attack systems windows role personal penetrati...  \n",
       "119  subdomains code information cors program star ...  \n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identified_repos_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "586de78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tag</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x4D31/awesome-threat-detection</td>\n",
       "      <td>secumon</td>\n",
       "      <td>connect logic spark trace instrument dispatch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xN3utr0n/Kanis</td>\n",
       "      <td>secumon</td>\n",
       "      <td>viruses elf sense information anomaly process ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>airbnb/binaryalert</td>\n",
       "      <td>secumon</td>\n",
       "      <td>aws threat match read status fire badge bucket...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>airbnb/streamalert</td>\n",
       "      <td>secumon</td>\n",
       "      <td>research aws automate source logic log support...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ait-aecid/logdata-anomaly-miner</td>\n",
       "      <td>secumon</td>\n",
       "      <td>raw information anomaly wiki deployment c ca d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>arch3rPro/PentestTools</td>\n",
       "      <td>pentest</td>\n",
       "      <td>connect page postgresql servers exe error java...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>whiterabb17/sifter</td>\n",
       "      <td>pentest</td>\n",
       "      <td>attack penetration code request information ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>hackThacker/advtools</td>\n",
       "      <td>pentest</td>\n",
       "      <td>attack pin code qr information website reverse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>rcallaby/Hacking-Study-Guide</td>\n",
       "      <td>pentest</td>\n",
       "      <td>attack systems windows role personal penetrati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>gotr00t0day/Gsec</td>\n",
       "      <td>pentest</td>\n",
       "      <td>subdomains code information cors program star ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                name      tag  \\\n",
       "0    0x4D31/awesome-threat-detection  secumon   \n",
       "1                    0xN3utr0n/Kanis  secumon   \n",
       "2                 airbnb/binaryalert  secumon   \n",
       "3                 airbnb/streamalert  secumon   \n",
       "4    ait-aecid/logdata-anomaly-miner  secumon   \n",
       "..                               ...      ...   \n",
       "115           arch3rPro/PentestTools  pentest   \n",
       "116               whiterabb17/sifter  pentest   \n",
       "117             hackThacker/advtools  pentest   \n",
       "118     rcallaby/Hacking-Study-Guide  pentest   \n",
       "119                 gotr00t0day/Gsec  pentest   \n",
       "\n",
       "                                                topics  \n",
       "0    connect logic spark trace instrument dispatch ...  \n",
       "1    viruses elf sense information anomaly process ...  \n",
       "2    aws threat match read status fire badge bucket...  \n",
       "3    research aws automate source logic log support...  \n",
       "4    raw information anomaly wiki deployment c ca d...  \n",
       "..                                                 ...  \n",
       "115  connect page postgresql servers exe error java...  \n",
       "116  attack penetration code request information ex...  \n",
       "117  attack pin code qr information website reverse...  \n",
       "118  attack systems windows role personal penetrati...  \n",
       "119  subdomains code information cors program star ...  \n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identified_repos_topics[identified_repos_topics['topics'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204a861c",
   "metadata": {},
   "source": [
    "https://umap-learn.readthedocs.io/en/latest/parameters.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c01edfac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         code program process demo colour c debug notic...\n",
       "1         process box generate efficient partition merge...\n",
       "2         attack pin code store compatibility authentica...\n",
       "3         html q youtube space api match access micropho...\n",
       "4         bank server free admin help list xray head fun...\n",
       "                                ...                        \n",
       "221966    software systems hackerrank bank applications ...\n",
       "221967    index liquibase driver page t5 trace app sprin...\n",
       "221968    connect code acl request information authentic...\n",
       "221969    api ml request core machine context arkit av d...\n",
       "221970    connect elements case servers documentation sc...\n",
       "Name: topics, Length: 218335, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset['topics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0d43f33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umap done 0.00011205673217773438\n",
      "bertopic done 0.00011324882507324219\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "fitting done 6672.580952167511\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "#cr_start()\n",
    "#word_doc_matrix = vectorizer.fit_transform(testset['topics'])\n",
    "#runtime_worddoc = cr_getrt()\n",
    "# Initiate UMAP\n",
    "cr_start()\n",
    "umap_model = UMAP(n_neighbors=30, \n",
    "                  n_components=2, #5\n",
    "                  min_dist=0.0, \n",
    "                  #metric='hellinger',  #cosine\n",
    "                  random_state=42)# Initiate BERTopic\n",
    "runtime_umap = cr_getrt()\n",
    "print(f\"umap done {runtime_umap}\")\n",
    "\n",
    "cr_start()\n",
    "#topic_model = BERTopic(umap_model=umap_model, language=\"english\", calculate_probabilities=False)# Run BERTopic model\n",
    "topic_model = BERTopic(language=\"english\", calculate_probabilities=False)# Run BERTopic model\n",
    "runtime_topic = cr_getrt()\n",
    "print(f\"bertopic done {runtime_topic}\")\n",
    "\n",
    "cr_start()\n",
    "topics, probabilities = topic_model.fit_transform(testset[testset['topics'].notna()]['topics'])\n",
    "runtime_fittr = cr_getrt()\n",
    "print(f\"fitting done {runtime_fittr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "611caea5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/manuel/d3tect-tools/Notebooks/raw_testdata_v1/bart_res_t2.3.1s_topics.pkl\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mto_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtopics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbart_res_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mt_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_topics\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m to_disk(probabilities, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbart_res_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_probabilities\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m to_disk(topic_model, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbart_res_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_topic_model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/d3tect-tools/Notebooks/shared_globals_functions.py:27\u001b[0m, in \u001b[0;36mto_disk\u001b[0;34m(obj, name)\u001b[0m\n\u001b[1;32m     25\u001b[0m file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(file)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pickle\u001b[49m(file)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_pickle'"
     ]
    }
   ],
   "source": [
    "to_disk(topics, f'bart_res_{t_name}_topics')\n",
    "to_disk(probabilities, f'bart_res_{t_name}_probabilities')\n",
    "to_disk(topic_model, f'bart_res_{t_name}_topic_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d440a779",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'from_disk_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m testmodel \u001b[38;5;241m=\u001b[39m \u001b[43mfrom_disk_results\u001b[49m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbart_res_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_topic_model\u001b[39m\u001b[38;5;124m'\u001b[39m, subdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m, t\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m testtopics \u001b[38;5;241m=\u001b[39m from_disk_results(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbart_res_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_topics\u001b[39m\u001b[38;5;124m'\u001b[39m, subdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m, t\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlist\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m testprob \u001b[38;5;241m=\u001b[39m from_disk_results(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbart_res_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_probabilities\u001b[39m\u001b[38;5;124m'\u001b[39m, subdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m, t\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlist\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'from_disk_results' is not defined"
     ]
    }
   ],
   "source": [
    "testmodel = from_disk(f'bart_res_{t_name}_topic_model', subdir='', t='bert')\n",
    "testtopics = from_disk(f'bart_res_{t_name}_topics', subdir='results', t='list')\n",
    "testprob = from_disk(f'bart_res_{t_name}_probabilities', subdir='results', t='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24066787",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtopics\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'topics' is not defined"
     ]
    }
   ],
   "source": [
    "len(topics)\n",
    "\n",
    "with pd.option_context('display.max_rows', 1000, 'display.max_columns', 20, 'display.max_colwidth', 1000):\n",
    "    display(identified_repos_topics.groupby('cluster_run').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49adf0c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This BERTopic instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get top 10 terms for a topic\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtopic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_topic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/d3tect-tools/venv/lib/python3.9/site-packages/bertopic/_bertopic.py:1437\u001b[0m, in \u001b[0;36mBERTopic.get_topic\u001b[0;34m(self, topic, full)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_topic\u001b[39m(\u001b[38;5;28mself\u001b[39m, topic: \u001b[38;5;28mint\u001b[39m, full: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Mapping[\u001b[38;5;28mstr\u001b[39m, Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]], \u001b[38;5;28mbool\u001b[39m]:\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Return top n words for a specific topic and their c-TF-IDF scores\u001b[39;00m\n\u001b[1;32m   1422\u001b[0m \n\u001b[1;32m   1423\u001b[0m \u001b[38;5;124;03m    Arguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1435\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m   1436\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1437\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1438\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m topic \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtopic_representations_:\n\u001b[1;32m   1439\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m full:\n",
      "File \u001b[0;32m~/d3tect-tools/venv/lib/python3.9/site-packages/bertopic/_utils.py:71\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(topic_model)\u001b[0m\n\u001b[1;32m     67\u001b[0m msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m instance is not fitted yet. Call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappropriate arguments before using this estimator.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m topic_model\u001b[38;5;241m.\u001b[39mtopics_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mtype\u001b[39m(topic_model)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[0;31mValueError\u001b[0m: This BERTopic instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# Get top 10 terms for a topic\n",
    "topic_model.get_topic(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344f124a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top topic keywords\n",
    "topic_model.visualize_barchart(top_n_topics=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39284908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize term rank decrease\n",
    "topic_model.visualize_term_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4e7023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize intertopic distance\n",
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2ed0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize connections between topics using hierachical clustering\n",
    "topic_model.visualize_hierarchy(top_n_topics=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25688ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize similarity using heatmap\n",
    "topic_model.visualize_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8ce89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize probability distribution\n",
    "topic_model.visualize_distribution(topic_model.probabilities_[0], min_probability=0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68969623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def max_fscore(d, dbg=False):\n",
    "    #max_fscore(results[[tag, 'cluster_run']].apply(tuple, axis=1).to_dict()\n",
    "    # key: (my_cluster, kmeans_cluster)\n",
    "    #d = {'a': (0, 0), 'b': (0, 1), 'c': (1, 1), 'd': (1, 3), 'e': (2, 2), 'f': (2, 2), 'g': (2, 0)}\n",
    "    #d = {'a': (0, 10), 'b': (0, 10), 'c': (1, 11), 'd': (1, 11), 'e': (1, 12), 'f': (2, 13), 'g': (3, 13)}\n",
    "    #d = {'a': (0, 100), 'b': (0, 100), 'c': (1, 101)}\n",
    "        \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    # Double loop to compare each repo with every other repo\n",
    "    already_processed = []\n",
    "    for outer in d.keys():\n",
    "        already_processed.append(outer)\n",
    "        for inner in d.keys():\n",
    "            if inner in already_processed:\n",
    "                # Repos are not compared to themselves and each repo should only be compared with each other repo once (i.e. a->b then b->a is not necessary anymore)\n",
    "                continue\n",
    "            my_cluster_outer = d[outer][0]\n",
    "            kmeans_outer = d[outer][1]\n",
    "            my_cluster_inner = d[inner][0]\n",
    "            kmeans_inner = d[inner][1]\n",
    "            #kmeans_inner_list = tag_list[my_cluster_inner]\n",
    "            if kmeans_outer == kmeans_inner: #kmeans_outer == kmeans_inner: # if inner clusterlabel == outer clusterlabel\n",
    "                # outer and inner were clustered into the same cluster\n",
    "                if my_cluster_outer == my_cluster_inner: # if inner my tag == outer my tag\n",
    "                    # outer and inner should be in the same cluster\n",
    "                    tp += 1\n",
    "                    if dbg: print(outer + '-' + inner + ': TP')\n",
    "                else:\n",
    "                    # outer and inner should be in different clusteres\n",
    "                    fp += 1\n",
    "                    if dbg: print(outer + '-' + inner + ': FP')\n",
    "            else:\n",
    "                # outer and inner were clustered into different clusters\n",
    "                if my_cluster_outer == my_cluster_inner:\n",
    "                    # outer and inner should be in the same cluster\n",
    "                    fn += 1\n",
    "                    if dbg: print(outer + '-' + inner + ': FN')\n",
    "                else:\n",
    "                    tn += 1\n",
    "                    if dbg: print(outer + '-' + inner + ': TN')\n",
    "    f1 = (2.0*tp) / (2.0*tp + fp + fn)\n",
    "    \n",
    "    try:\n",
    "        fpr = fp / (fp + tn)\n",
    "        tnr = 1 - fpr # tn / (tn + fp)\n",
    "    except ZeroDivisionError as e:\n",
    "        try:\n",
    "            tnr = tn / (tn + fp)\n",
    "            fpr = 1 - tnr\n",
    "        except ZeroDivisionError as e:\n",
    "            tnr = 'N/A'\n",
    "            fpr = 'N/A'\n",
    "    \n",
    "\n",
    "    \n",
    "    tpr = tp / (tp + fn) #recall / hit rate\n",
    "\n",
    "    ppv = tp / (tp + fp) # precision\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    fnr = fn / (fn + tp) # miss\n",
    "    \n",
    "    return { 'tp': tp,\n",
    "            'tn': tn,\n",
    "            'fp': fp,\n",
    "            'fn': fn,\n",
    "            'f1': f1,\n",
    "            'accuracy': accuracy,\n",
    "            'ppv': ppv,\n",
    "            'fpr': fpr,\n",
    "            'tpr': tpr,\n",
    "            'tnr': tnr,\n",
    "            'fnr': fnr\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baf1f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset['cluster_run'] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592c98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "identified_repos_topics = pd.merge(identified_repos, testset[[\"name\", \"cluster_run\"]], on=\"name\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a020b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = identified_repos_topics[identified_repos_topics['cluster_run'].notna()]\n",
    "results = results[results['cluster_run'] != -1]\n",
    "\n",
    "stats = {'type': \"BART\",\n",
    "         'testset': t_name,\n",
    "         'version': version,\n",
    "         'size':'N/A'\n",
    "        }\n",
    "\n",
    "my_results = []\n",
    "\n",
    "lo_tags = [c for c in identified_repos.columns if 'tag' in c]\n",
    "for tag in lo_tags:        \n",
    "    prediction = stats\n",
    "    prediction['tag'] = tag\n",
    "    prediction.update(max_fscore(results[[tag, 'cluster_run']].apply(tuple, axis=1).to_dict()))\n",
    "    #print(prediction)\n",
    "    my_results.append(prediction.copy())\n",
    "    \n",
    "pd.DataFrame.from_dict(my_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eb4fef",
   "metadata": {
    "lines_to_next_cell": 0,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "with pd.option_context('display.max_rows', 1000, 'display.max_columns', 20, 'display.max_colwidth', 1000):\n",
    "    display(identified_repos_topics.sort_values('cluster_run'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc33eef",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
